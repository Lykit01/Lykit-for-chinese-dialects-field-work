{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-19T10:21:33.303894Z",
     "start_time": "2019-03-19T10:21:32.379933Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.sans-serif']=['SimHei'] #用来显示中文\n",
    "plt.rcParams['axes.unicode_minus']=False #用来正常显示负号\n",
    "import re,random\n",
    "from tkinter import *\n",
    "import tkinter.filedialog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-19T10:21:33.348011Z",
     "start_time": "2019-03-19T10:21:33.303894Z"
    }
   },
   "outputs": [],
   "source": [
    "#辅助函数\n",
    "def get_check_type(x):#check提前检查纯数字、日期等不规范的记法,并给出解决办法\n",
    "    if isinstance(x,pd.Timestamp) or isinstance(x,pd.datetime):\n",
    "        return \"错成excel时间格式了，请在音节前加'/'，如'/jan22'\"\n",
    "    elif isinstance(x,int):\n",
    "        return \"错成纯数字了\"\n",
    "    elif '\\\\' in x:\n",
    "        return \"请不要用'\\\\',改用'/'\"\n",
    "    elif '/' in x.strip('/'):\n",
    "        return \"请不要在音节中用'/'，如一词声母有变体，请拆成两个条目\"\n",
    "    else:\n",
    "        return \"\"\n",
    "def init(x):\n",
    "    return x\n",
    "def init_examples(x,ned,example_num):\n",
    "    return ' / '.join(sorted(list(ned.loc[ned['init']==x,'item'].unique()),key=len)[:example_num])\n",
    "\n",
    "def fnl_phon_sort(arr,fnl_num_dict):\n",
    "    for i in range(len(arr)):\n",
    "        for j in range(i+1,len(arr)):\n",
    "            if fnl_num_dict[arr[i]]>fnl_num_dict[arr[j]]:\n",
    "                arr[i],arr[j]=arr[j],arr[i]\n",
    "def fnl_num(fnl,medials,fnl_sect_dict):\n",
    "    num=[0,0,0,0]\n",
    "    num[0]=medials.index(fnl_sect_dict[fnl][0])\n",
    "    num[0]=0 if num[0]==-1 else num[0]\n",
    "    num[1]=vowel_num(fnl_sect_dict[fnl][1]+fnl_sect_dict[fnl][2])*10\n",
    "    num[2]=vowel_num(fnl_sect_dict[fnl][3])*100\n",
    "    num[3]=[\"\",\"m\",\"n\",\"ng\",\"p\",\"t\",\"k\",\"?\"].index(fnl_sect_dict[fnl][4])*10000000\n",
    "    return sum(num)\n",
    "def vowel_num(vowel):\n",
    "    if vowel==\"\":\n",
    "        return 0\n",
    "    if vowel in [\"z\",\"v\",\"l\",\"m\",\"n\",\"ng\"]:\n",
    "        pos=[\"z\",\"v\",\"l\",\"m\",\"n\",\"ng\"].index(vowel)\n",
    "        return pos*1000000\n",
    "    ipa_fnl_str ='''i~,y~,i#~,u#~,u=~,u~;I~,Y~,,,U~,;e~,e@~,e#~,o#~,e>~,o~;E~,,e=~,,,o=~;e+~,e+@~,e+#~,o+#~,o+$~,o+~;a^~,,A^~,,,;a~,a@~,A~,,a>~,a>@~;i<~,i>~,y<~,y>~,,;\n",
    "    i,y,i#,u#,u=,u;I,Y,,,U,;e,e@,e#,o#,e>,o;E,,e=,,,o=;e+,e+@,e+#,o+#,o+$,o+;a^,,A^,,,;a,a@,A,,a>,a>@;i<,i>,y<,y>,,;\n",
    "    i:,y:,i#:,u#:,u=:,u:;I:,Y:,,,U:,;e:,e@:,e#:,o#:,e>:,o:;E:,,e=:,,,o=:;e+:,e+@:,e+#:,o+#:,o+$:,o+:;a^:,,A^:,,,;a:,a@:,A:,,a>:,a>@:;i<:,i>:,y<:,y>:,,'''\n",
    "    ipa_fnl=ipa_fnl_str.split(\";\")\n",
    "    for i,v in enumerate(ipa_fnl):\n",
    "        if vowel in v.split(\",\"):\n",
    "            pos=v.split(\",\").index(vowel)\n",
    "            num=(len(ipa_fnl)-i)*10+pos\n",
    "            if vowel[-1]==\"~\":\n",
    "                num*=100\n",
    "            return num\n",
    "    return random.randint(10000,20000)    \n",
    "\n",
    "def get_multi_tones(x):\n",
    "    xs=x.split(' ')\n",
    "    for k in range(len(xs)):\n",
    "        for i in range(len(xs[k])-1,0,-1):\n",
    "            if xs[k][i] not in '0123456789':\n",
    "                if xs[k][i] in '?ptk':\n",
    "                    xs[k]=xs[k][i+1:]+'入'\n",
    "                else:xs[k]=xs[k][i+1:]  \n",
    "                break\n",
    "    return ' '.join(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-19T10:21:33.535536Z",
     "start_time": "2019-03-19T10:21:33.348011Z"
    }
   },
   "outputs": [],
   "source": [
    "def execute():\n",
    "    global DATA_READY\n",
    "    if not DATA_READY:\n",
    "        note_lb.config(text=\"源数据没有选择对，请重新选择！\")\n",
    "    else:\n",
    "        analyse()\n",
    "\n",
    "#分析程序\n",
    "def analyse():\n",
    "    try:\n",
    "        global SOURCE\n",
    "        global TARGETSHEET\n",
    "        global EXAMPLE_NUM\n",
    "        global INIT_EXCEP\n",
    "        global FNL_EXCEP\n",
    "        global TONE_EXCEP\n",
    "        excep_val=[int(INIT_EXCEP.get()),int(FNL_EXCEP.get()),int(TONE_EXCEP.get())]\n",
    "        example_num=int(EXAMPLE_NUM.get())\n",
    "        data=pd.read_excel(SOURCE,sheet_name=TARGETSHEET.get())\n",
    "        #清洗\n",
    "        #列名重命名\n",
    "        init_col=data.columns\n",
    "        now_col=[\"\"]*len(init_col)\n",
    "        for i,col in enumerate(init_col):\n",
    "            if re.match(u\".*[词项|汉字|词目|词|字].*\",col):\n",
    "                now_col[i]=\"item\"\n",
    "            elif re.match(u\".*记音.*\",col):\n",
    "                now_col[i]=\"rec\"\n",
    "            elif re.match(u\".*文白.*\",col):\n",
    "                now_col[i]=\"wenbai\"\n",
    "            elif re.match(u\".*义.*\",col):\n",
    "                now_col[i]=\"meaning\"\n",
    "            elif re.match(u\".*备注.*\",col):\n",
    "                now_col[i]=\"note\"\n",
    "            else:\n",
    "                now_col[i]=col\n",
    "        col_dict={init_col[i]:now_col[i] for i in range(len(init_col))}\n",
    "        data.rename(columns=col_dict,inplace=True)\n",
    "        #去除空白项\n",
    "        data=data.fillna(\"\")\n",
    "\n",
    "        data[\"check\"]=data[\"rec\"].apply(get_check_type)\n",
    "        data[\"rec\"]=data[\"rec\"].apply(lambda x:str(x))#把记录全部变为字符串\n",
    "        data=data[data[\"rec\"]!=\"\"]#去掉空行\n",
    "        #去除重复项,直接删了\n",
    "        data=data.drop_duplicates([\"item\",\"rec\"])\n",
    "        data.sort_values(by=[\"item\",\"rec\"],ascending=False)\n",
    "        data=data.reset_index(drop=True)#重新排索引，把中间之前删掉的索引补回来\n",
    "        #增添新列\n",
    "        extra_col=now_col+[\"check\",\"std_syl\",\"init\",\"center\",\"tail\",\"tone\"]\n",
    "        data=data.reindex(columns=extra_col,fill_value=\"\")\n",
    "        data.loc[:,\"sylcnt\"]=0\n",
    "        #规范记音,切分多音节，标注，切分声韵调\n",
    "        #判断所用的字符\n",
    "        fnl_sect_dict={}#后面做韵母的语音学排序会用到\n",
    "        std_letters=\"qwertyuiopasdfghjklzxcvbnmQWERTYUIOPASDFGHJKLZXCVBNM0123456789~!?@#$^&<>*=+:\"\n",
    "        for idx,syl in enumerate(data[\"rec\"]):\n",
    "            new_syl=\"\"\n",
    "            for i,letter in enumerate(syl):\n",
    "                if letter in std_letters:\n",
    "                    new_syl+=letter\n",
    "            #正则切分\n",
    "            pattern=re.compile(\"(\\??)([qwrtypsdfghjklzxcvbnmQWRTYPSDFGHJKLZXCVBNM>#\\!\\$\\^\\*\\+]{0,4})([aeiouAEIOUw]?[<>=#~@:\\$\\^\\*\\+]*)([aeiouAEIOUmnlzv]|ng){1}([<>=#~@:\\$\\^\\*\\+]*)([aeiouAEIOU]?[<>=#~@:\\$\\^\\*\\+]*)([mnptk\\?]|ng)?(\\d+)\")\n",
    "            results=pattern.findall(new_syl)\n",
    "            for i in range(len(results)):#细节调整\n",
    "                results[i]=list(results[i])\n",
    "                result=results[i]\n",
    "                if result[0]+result[1] in [\"\",'w']:#零声母的情况，默认补一个？，避免'?'与''重复计数\n",
    "                    result[0]=\"?\"\n",
    "                if len(result[1])>0 and result[1][-1]=='w':\n",
    "                    result[1]=result[1][:-1]\n",
    "                    result[2]='w'+result[2]#w算作介音\n",
    "                if result[2]!=\"\" and result[3] in [\"n\",\"ng\",\"m\"]:\n",
    "                    result[6]=result[3]\n",
    "                    result[3]=result[2]\n",
    "                    result[2]=\"\"\n",
    "                elif result[3] in [\"n\",\"ng\",\"m\"] and result[6] in [\"n\",\"ng\",\"m\"]:\n",
    "                    result[3]=\"\"\n",
    "                if result[6] in [\"p\",\"t\",\"k\",\"?\"]:\n",
    "                    result[7]+=\"入\"\n",
    "                if result[2]!=\"\" and result[3] in \"iuyIUY\" and result[5]==\"\":\n",
    "                    result[5]=result[3]+result[4]\n",
    "                    result[4]=\"\"\n",
    "                    result[3]=result[2]\n",
    "                    result[2]=\"\"\n",
    "\n",
    "            #切分声韵调\n",
    "            if len(results)==1:\n",
    "                sylsects=results[0]\n",
    "                data.loc[idx,\"std_syl\"]=\"\".join(filter(None,sylsects)).strip(\"入\")\n",
    "                data.loc[idx,\"init\"]=sylsects[0]+sylsects[1]\n",
    "                data.loc[idx,\"center\"]=sylsects[2]+sylsects[3]+sylsects[4]+sylsects[5]\n",
    "                data.loc[idx,\"tail\"]=sylsects[6]\n",
    "                data.loc[idx,\"tone\"]=sylsects[7]\n",
    "                data.loc[idx,\"sylcnt\"]=1\n",
    "                fnl=sylsects[2]+sylsects[3]+sylsects[4]+sylsects[5]+sylsects[6]\n",
    "                if fnl not in fnl_sect_dict:\n",
    "                    fnl_sect_dict[fnl]=[sylsects[2],sylsects[3],sylsects[4],sylsects[5],sylsects[6]]\n",
    "\n",
    "            elif len(results)>1:\n",
    "                data.loc[idx,\"sylcnt\"]=len(results)\n",
    "                poly_sects=[]\n",
    "                for j,result in enumerate(results):\n",
    "                    row={data.columns[i]:\"\" for i in range(len(data.columns))}\n",
    "                    row[\"item\"]=data.loc[i,\"item\"]+str(j+1)\n",
    "                    tmp_syl=\"\".join(filter(None,result))\n",
    "                    tmp_syl=tmp_syl.strip(\"入\")\n",
    "                    poly_sects.append(tmp_syl)\n",
    "                    row[\"std_syl\"]=tmp_syl\n",
    "                    row[\"init\"]=result[0]+result[1]\n",
    "                    row[\"center\"]=result[2]+result[3]+result[4]+result[5]\n",
    "                    row[\"tail\"]=result[6]\n",
    "                    row[\"tone\"]=result[7]\n",
    "                    row[\"sylcnt\"]=1\n",
    "                    data=data.append(row,ignore_index=True)\n",
    "                    fnl=result[2]+result[3]+result[4]+result[5]+result[6]\n",
    "                    if fnl not in fnl_sect_dict:\n",
    "                        fnl_sect_dict[fnl]=[result[2],result[3],result[4],result[5],result[6]]\n",
    "                data.loc[idx,\"std_syl\"]=\" \".join(poly_sects)\n",
    "        #统计多音字/词\n",
    "        item_cnt=data.groupby([\"item\"],as_index=False)[\"item\"].agg({\"ppcnt\":\"count\"})\n",
    "        #item_cnt=data[\"item\"].value_counts()\n",
    "        data=pd.merge(data,item_cnt,left_on=[\"item\"],right_on=[\"item\"],how=\"left\")\n",
    "        #程序标注需要修改的项\n",
    "        data.loc[data[\"rec\"]!=data[\"std_syl\"],\"check\"]+=\"  记音不规范\"\n",
    "        data.loc[data[\"rec\"]==\"\",\"check\"]=\"\"#对于多音节词拆分出来的单音节不需要检查，直接检查多音节就好了\n",
    "        #去除没有切分的多音节词\n",
    "        #ssd:single syl data\n",
    "        ssd=data[data[\"center\"]!=\"\"].copy()#这里用副本，避免下面对ssd进行筛选时触发复制警告\n",
    "        #包含例外的音节\n",
    "        whole_syl_list=ssd[\"std_syl\"].value_counts()\n",
    "        #声韵组合分析\n",
    "        #init_and_fnl_list=ssd.groupby([\"init\",\"center\",\"tail\"])[\"item\"].count().sort_values(ascending=False)\n",
    "        init_and_fnl_list=(ssd.loc[:,\"init\"]+ssd.loc[:,\"center\"]+ssd.loc[:,\"tail\"]).value_counts()\n",
    "        #包括例外的声母\n",
    "        init_list=ssd[\"init\"].value_counts()\n",
    "        #包含例外的韵母\n",
    "        ssd.loc[:,\"fnl\"]=ssd.loc[:,\"center\"]+ssd.loc[:,\"tail\"]#两列直接相加要改为这种\n",
    "        fnl_list=ssd[\"fnl\"].value_counts()\n",
    "        #包含例外的声调\n",
    "        tone_list=ssd[\"tone\"].value_counts()\n",
    "        tail_list=ssd[\"tail\"].value_counts()\n",
    "\n",
    "        #不包括例外的声母\n",
    "        no_excep_init=init_list[init_list>excep_val[0]]\n",
    "        #不包含例外的韵母\n",
    "        no_excep_fnl=fnl_list[fnl_list>excep_val[1]]\n",
    "        #不包含例外的声调\n",
    "        no_excep_tone=tone_list[tone_list>excep_val[2]]\n",
    "\n",
    "        #no_excep_data\n",
    "        ned=ssd[ssd[\"init\"].isin(no_excep_init.index)&ssd[\"fnl\"].isin(no_excep_fnl.index)&ssd[\"tone\"].isin(no_excep_tone.index)].copy()\n",
    "        #不包含例外的音节\n",
    "        no_excep_whole_syl=ned[\"std_syl\"].value_counts()\n",
    "        #不包含例外的声韵组合个数\n",
    "        no_excep_init_and_fnl=(ned.loc[:,\"init\"]+ned.loc[:,\"fnl\"]).value_counts()\n",
    "        #不包含例外的韵尾个数\n",
    "        no_excep_tail=ned[\"tail\"].value_counts()\n",
    "\n",
    "        #对含例外的记录标上记号\"例外\"，回到手工检查这一步\n",
    "        data.loc[data[\"sylcnt\"]==1&-data[\"std_syl\"].isin(no_excep_whole_syl.index),\"check\"]+=\"声韵调例外\"\n",
    "        survey=pd.Series({\"记录的单音节数\":data.loc[data[\"sylcnt\"]==1,\"std_syl\"].count(),\n",
    "                      \"记录的多音节词数\":data.loc[data[\"sylcnt\"]>1,\"std_syl\"].count(),\n",
    "                     \"拆分多音节得到的单音节\":data.loc[data[\"rec\"]==\"\",\"std_syl\"].count(),\n",
    "                      \"多音字/词的个数\":len(data.loc[(data[\"ppcnt\"]>1) & (data[\"rec\"]!=\"\"),\"item\"].unique()),\n",
    "                    \"音节数(去重,含例外)\":len(whole_syl_list),\n",
    "                      \"声韵组合数(去重,含例外)\":len(init_and_fnl_list),\n",
    "                      \"声母数(去重,含例外)\":len(init_list),\n",
    "                      \"韵母数(去重,含例外)\":len(fnl_list),\n",
    "                      \"声调数(去重,含例外)\":len(tone_list),\n",
    "                      \"辅音韵尾数(去重,含例外)\":len(tail_list),\n",
    "                   \"音节数(去重,不含例外)\":len(no_excep_whole_syl),\n",
    "                      \"声韵组合数(去重,不含例外)\":len(no_excep_init_and_fnl),\n",
    "                      \"声母数(去重,不含例外)\":len(no_excep_init),\n",
    "                      \"韵母数(去重,不含例外)\":len(no_excep_fnl),\n",
    "                      \"声调数(去重,不含例外)\":len(no_excep_tone),\n",
    "                      \"辅音韵尾数(去重,不含例外)\":len(no_excep_tail)\n",
    "                    })\n",
    "        #语音学排序\n",
    "        #声母Series\n",
    "        init_tmp=list(no_excep_init.index)#排除例外后的声母列表\n",
    "        init_phon=[]#最后的声母列表\n",
    "        init_df=pd.DataFrame(init_tmp,index=init_tmp)\n",
    "        ipa_init_part_list=[\"双唇\",\"唇齿\",\"舌齿\",\"舌尖前\",\"舌尖中\",\"舌尖后\",\"舌叶\",\"舌面前\",\"舌面中\",\"舌面后\",\"小舌\",\"喉壁\",\"喉门\"]\n",
    "        ipa_init_manner_list=[\"不送清塞\",\"送气清塞\",\"不送浊塞\",\"送气浊塞\",\"不送清塞擦\",\"送气清塞擦\",\"不送浊塞擦\",\"送气浊塞擦\",\"鼻\",\"颤音\",\"闪音\",\"边\",\"清边擦\",\"浊边擦\",\"清擦\",\"浊擦\",\"通展\",\"通圆\"]\n",
    "        ipa_init_str = \"p,ph,b,bh,,,,,m,,,,,,p*,b*,,;,,,,pf,pfh,bv,bvh,mg,,,,,,f,v,v$,;,,,,t>,t>h,d>,d>h,,,,,,,s>,z>,,;,,,,ts,tsh,dz,dzh,,,,,,,s,z,,;t,th,d,dh,,,,,n,r,r*,l,ls,l#,,,r$,;tr,trh,dr,drh,tsr,tsrh,dzr,dzrh,nr,,r^,lr,,,sr,zr,rr,;,,,,tss,tssh,dzz,dzzh,,,,,,,ss,zz,,;tj,tjh,dj,djh,tcj,tcjh,dzj,dzjh,nj,,,,,,cj,zj,,;c,ch,c!,c!h,,,,,nc,,,lc,,,c#,jj,j,y$;k,kh,g,gh,,,,,ng,,,,,,x,x!,w!,w$;q,qh,G,Gh,,,,,N,R,,,,,X,X!,,;,,,,,,,,,,,,,,h*,h*!,,;?,?h,,,,,,,,,,,,,h,h!,,\"\n",
    "        ipa_init=[s.split(\",\") for s in ipa_init_str.split(\";\")]\n",
    "        for i in range(len(ipa_init)):\n",
    "            for j in range(len(ipa_init[0])):\n",
    "                letter=ipa_init[i][j]\n",
    "                if letter!='' and letter in init_tmp:\n",
    "                    init_df.loc[letter,'发音部位']=ipa_init_part_list[i]\n",
    "                    init_df.loc[letter,'发音方法']=ipa_init_manner_list[j]\n",
    "                    init_phon.append(letter)\n",
    "        #不在标准国际音标表中的声母\n",
    "        init_phon+=list(init_df.loc[init_df['发音方法'].isna(),0])\n",
    "        init_df.loc[init_df['发音部位'].isna(),'发音部位']=init_df.loc[:,0]\n",
    "        init_df.loc[init_df['发音方法'].isna(),'发音方法']='其他'\n",
    "        init_table=init_df.groupby(['发音部位','发音方法'])[0].sum().unstack(1).reindex(index=ipa_init_part_list+init_tmp,columns=ipa_init_manner_list+['其他'])\n",
    "        init_table=init_table.dropna(how='all').dropna(how='all',axis=1).fillna('')\n",
    "        #含例字的声母表\n",
    "        init_table_with_examples=init_table.transform([init,init_examples],ned=ned,example_num=example_num)\n",
    "        #韵母\n",
    "\n",
    "        fnl_phon=list(no_excep_fnl.index)#fnl转换格式\n",
    "        #处理介音问题\n",
    "        medials=set()#介音\n",
    "        for fnl in fnl_phon:\n",
    "            medials.add(fnl_sect_dict[fnl][0])\n",
    "        medials=list(medials)\n",
    "        medials.sort()\n",
    "        #韵母排序\n",
    "        fnl_num_dict={}\n",
    "        for fnl in fnl_phon:\n",
    "            fnl_num_dict[fnl]=fnl_num(fnl,medials,fnl_sect_dict)\n",
    "        fnl_phon_sort(fnl_phon,fnl_num_dict)\n",
    "        for i in range(len(fnl_phon)-1,0,-1):\n",
    "            fnl=fnl_phon[i]\n",
    "            if fnl_sect_dict[fnl][4] not in ['p','t','k','?']:\n",
    "                break\n",
    "        fnl_phon_shu=fnl_phon[:i+1]\n",
    "        fnl_phon_cu=fnl_phon[i+1:]\n",
    "        #韵母表Table 20190317\n",
    "        fnl_table_list=[]\n",
    "        fnl_articulation_dict={}\n",
    "        last_dval=0\n",
    "        fnl_base=[]#韵基\n",
    "        for fnl in fnl_phon:\n",
    "            dval=fnl_num_dict[fnl]//10\n",
    "            if dval!=last_dval:\n",
    "                last_dval=dval\n",
    "                fnl_base.append(fnl)\n",
    "                fnl_table_list.append([\"\" for _ in medials])\n",
    "            mval=fnl_num_dict[fnl]%10\n",
    "            fnl_table_list[-1][mval]=fnl\n",
    "            fnl_articulation_dict[fnl]=(fnl_base[-1],medials[mval])\n",
    "        fnl_table=pd.DataFrame(fnl_table_list,index=fnl_base,columns=medials)\n",
    "        #含例字的韵母表\n",
    "        new_index=[]\n",
    "        for x in fnl_base:\n",
    "            new_index+=[x]+[x+'例字']\n",
    "        fnl_table_with_examples=fnl_table.reindex(index=new_index).fillna('')\n",
    "        for fnl in fnl_phon:\n",
    "            options=list(ned.loc[ned['fnl']==fnl,'item'].unique())\n",
    "            fnl_table_with_examples.loc[fnl_articulation_dict[fnl][0]+'例字',\n",
    "                fnl_articulation_dict[fnl][1]]=' / '.join(sorted(options,key=len)[:example_num])\n",
    "        #声调\n",
    "        tone_phon=list(no_excep_tone.index)\n",
    "        tone_phon.sort(key=lambda x:x[-1])\n",
    "        for i in range(len(tone_phon)-1,0,-1):\n",
    "            if tone_phon[i][-1]!=\"入\":break\n",
    "        tone_phon_shu=tone_phon[:i+1]\n",
    "        tone_phon_cu=tone_phon[i+1:]\n",
    "        tone_phon=pd.DataFrame(tone_phon,index=tone_phon,columns=['调值'])\n",
    "        tone_phon['例字']=tone_phon['调值'].apply(lambda x:' / '.join(sorted(list(ned.loc[ned['tone']==x,'item'].unique()),key=len)[:example_num]))\n",
    "        #同音字表 新版20190318\n",
    "        hpp_tuples=list(zip([x for x in fnl_phon_shu for i in range(len(tone_phon_shu))]+[x for x in fnl_phon_cu for i in range(len(tone_phon_cu))],\n",
    "                        tone_phon_shu*len(fnl_phon_shu)+tone_phon_cu*len(fnl_phon_cu)))\n",
    "        hpp_index=pd.MultiIndex.from_tuples(hpp_tuples,names=[\"韵母\",\"声调\"])\n",
    "        #homophone_table=ned.groupby(['fnl','tone','init'])['item'].apply(lambda x:' // '.join(x))\n",
    "        #homophone_count_table=ned.groupby(['fnl','tone','init'])['item'].count()\n",
    "        homophone_all=ned.groupby(['fnl','tone','init'])['item'].apply(lambda x:str(x.count())+' // '+' // '.join(x))\n",
    "        homophone_all=homophone_all.unstack(2).reindex(index=hpp_index,columns=init_phon)\n",
    "        homophone_all=homophone_all.fillna('')\n",
    "        #调型\n",
    "        tone_match_init_fnl=ned.groupby(['fnl','init'])['tone'].apply(lambda x:' / '.join(x))\n",
    "        tone_match_init_fnl=tone_match_init_fnl.unstack(1).reindex(index=fnl_phon,columns=init_phon)\n",
    "        tone_match_init_fnl=tone_match_init_fnl.fillna('')\n",
    "        #多音节声调组合\n",
    "        #二音节声调组合\n",
    "        two_syl_data=data.loc[data['sylcnt']==2,:].copy()\n",
    "        two_syl_data.loc[:,'itemrec']=two_syl_data.loc[:,'item']+': '+two_syl_data.loc[:,'std_syl']\n",
    "\n",
    "        two_syl_data.loc[:,'two_tones']=two_syl_data.loc[:,'std_syl'].apply(get_multi_tones)\n",
    "        two_syl_data.loc[:,'firsttone']=two_syl_data.loc[:,'two_tones'].apply(lambda x:x.split(' ')[0])\n",
    "        two_syl_data.loc[:,'secondtone']=two_syl_data.loc[:,'two_tones'].apply(lambda x:x.split(' ')[1])\n",
    "        two_syl_table=two_syl_data.groupby(['firsttone','secondtone'])['itemrec'].apply(lambda x:' // '.join(x))\n",
    "        two_syl_table=two_syl_table.unstack(1)\n",
    "        #三音节声调组合\n",
    "        tri_syl_data=data.loc[data['sylcnt']==3,:].copy()\n",
    "        tri_syl_data.loc[:,'itemrec']=tri_syl_data.loc[:,'item']+': '+tri_syl_data.loc[:,'std_syl']\n",
    "        tri_syl_data.loc[:,'tri_tones']=tri_syl_data.loc[:,'std_syl'].apply(get_multi_tones)\n",
    "        tri_syl_data.loc[:,'firsttone']=tri_syl_data.loc[:,'tri_tones'].apply(lambda x:x.split(' ')[0])\n",
    "        tri_syl_data.loc[:,'secondtone']=tri_syl_data.loc[:,'tri_tones'].apply(lambda x:x.split(' ')[1])\n",
    "        tri_syl_data.loc[:,'thirdtone']=tri_syl_data.loc[:,'tri_tones'].apply(lambda x:x.split(' ')[2])\n",
    "        tri_syl_table=tri_syl_data.groupby(['firsttone','secondtone','thirdtone'])['itemrec'].apply(lambda x:' // '.join(x))\n",
    "        tri_syl_table=tri_syl_table.unstack(2)\n",
    "        #要输出的结果表\n",
    "        nowstr=datetime.now().strftime(\"%m%d\")\n",
    "        save_path=SOURCE.split('.xls')[0]+'处理结果'+nowstr+\".xlsx\"\n",
    "        writer=pd.ExcelWriter(save_path)\n",
    "        data.to_excel(writer,sheet_name='切分表',index=False,header=True)\n",
    "\n",
    "        sv_cols=['项目','计数','','声母含例外','计数','声母','计数','韵母含例外','计数','韵母','计数','声调含例外','计数','声调','计数','韵尾含例外','计数','韵尾','计数']\n",
    "        pd.DataFrame([['']*len(sv_cols) for i in range(2)],columns=sv_cols).to_excel(writer,index=False,sheet_name='概况')\n",
    "        survey.to_excel(writer,header=False,sheet_name='概况',startrow=1,)\n",
    "        init_list.to_excel(writer,header=False,sheet_name='概况',startrow=1,startcol=3)\n",
    "        no_excep_init.to_excel(writer,header=False,sheet_name='概况',startrow=1,startcol=5)\n",
    "        fnl_list.to_excel(writer,header=False,sheet_name='概况',startrow=1,startcol=7)\n",
    "        no_excep_fnl.to_excel(writer,header=False,sheet_name='概况',startrow=1,startcol=9)\n",
    "        tone_list.to_excel(writer,header=False,sheet_name='概况',startrow=1,startcol=11)\n",
    "        no_excep_tone.to_excel(writer,header=False,sheet_name='概况',startrow=1,startcol=13)\n",
    "        tail_list.to_excel(writer,header=False,sheet_name='概况',startrow=1,startcol=15)\n",
    "        no_excep_tail.to_excel(writer,header=False,sheet_name='概况',startrow=1,startcol=17)\n",
    "\n",
    "        init_table_with_examples.to_excel(writer,sheet_name='音系')\n",
    "        fnl_table_with_examples.to_excel(writer,sheet_name='音系',startrow=len(init_table_with_examples.index)+4)\n",
    "        tone_phon.to_excel(writer,sheet_name='音系',startrow=len(init_table_with_examples.index)+len(fnl_table_with_examples)+8)\n",
    "\n",
    "        homophone_all.to_excel(writer,sheet_name='同音字表')\n",
    "        tone_match_init_fnl.to_excel(writer,sheet_name='音节配调表')\n",
    "        two_syl_table.to_excel(writer,sheet_name='声调组合表')\n",
    "        tri_syl_table.to_excel(writer,sheet_name='声调组合表',startcol=len(two_syl_table)+4)\n",
    "        \n",
    "        #联系作者\n",
    "        add='https://github.com/Lykit01/Lykit-for-chinese-dialects-field-work'\n",
    "        about=pd.Series(['@Hue Zhang','3275803255@qq.com',add,'如有问题请联系我！'],index=['author','email','github',''])\n",
    "        about.to_excel(writer,sheet_name='关于')\n",
    "        \n",
    "        writer.save()\n",
    "        note_lb.config(text=\"分析完毕，结果保存在:\"+save_path)\n",
    "    except Exception:\n",
    "        note_lb.config(text=\"表内数据有误！请检查源数据！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-19T10:21:33.549017Z",
     "start_time": "2019-03-19T10:21:33.535536Z"
    }
   },
   "outputs": [],
   "source": [
    "#选择源文件\n",
    "def choose_files():\n",
    "    #每次点击选择源文件，都会清空之前的选择,并且把wishlistname、data_ready等清空\n",
    "    file_lb.config(text=\"\")\n",
    "    global TARGETSHEET\n",
    "    global SOURCE\n",
    "    global DATA_READY\n",
    "    SOURCE=\"\"\n",
    "    DATA_READY=False\n",
    "    \n",
    "    filename=tkinter.filedialog.askopenfilenames()\n",
    "    if len(filename)!=1:\n",
    "        lb_text=\"你选择了%d个文件，请只选择1个文件。\"%len(filename)\n",
    "    elif filename[0].split('.')[-1] not in ['xls','xlsx','xlsm']:\n",
    "        lb_text=\"请选择excel文件，后缀名包括xls,xlsx,xlsm等。\"\n",
    "    else:\n",
    "        try:\n",
    "            tryreadfile=pd.read_excel(filename[0],sheet_name=TARGETSHEET.get())\n",
    "        except Exception:\n",
    "            lb_text='选取文件不对或excel中没有唯一的名为'+TARGETSHEET.get()+'的sheet。'\n",
    "        else:\n",
    "            SOURCE=filename[0]\n",
    "            DATA_READY=True\n",
    "            lb_text=\"数据已经准备好了！\"\n",
    "            file_lb.config(text=\"您选择的文件是：\"+filename[0])\n",
    "    note_lb.config(text=lb_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-19T10:22:44.649945Z",
     "start_time": "2019-03-19T10:21:33.549017Z"
    }
   },
   "outputs": [],
   "source": [
    "root=Tk()\n",
    "root.title(\"Lykit01:cdfw\")\n",
    "root.geometry(\"420x140\")\n",
    "SOURCE=''\n",
    "DATA_READY=False\n",
    "save_path=\"\"\n",
    "\n",
    "#提示分析中间的问题\n",
    "note_lb=Label(root,text=\"请选择1个源文件,并在下面填入要处理的sheet名以及例外判断标准。\")\n",
    "note_lb.place(x=200,y=10,anchor=\"center\")\n",
    "#文件提示\n",
    "file_lb=Label(root,text='')\n",
    "file_lb.place(x=200,y=30,anchor=\"center\")\n",
    "#输入sheet名\n",
    "Label(root,text='要处理的sheet名').place(x=50,y=60,anchor=\"center\")\n",
    "TARGETSHEET=StringVar()\n",
    "TARGETSHEET.set('词表')\n",
    "Entry(root,textvariable=TARGETSHEET,width=8).place(x=150,y=60,anchor=\"center\")\n",
    "Label(root,text='例字数目').place(x=230,y=60,anchor=\"center\")\n",
    "EXAMPLE_NUM=StringVar()\n",
    "EXAMPLE_NUM.set(5)\n",
    "Entry(root,textvariable=EXAMPLE_NUM,width=4).place(x=300,y=60,anchor=\"center\")\n",
    "\n",
    "Label(root,text='例外判定标准:声母').place(x=50,y=90,anchor=\"center\")\n",
    "INIT_EXCEP=StringVar()\n",
    "INIT_EXCEP.set(0)\n",
    "Entry(root,textvariable=INIT_EXCEP,width=4).place(x=150,y=90,anchor=\"center\")\n",
    "Label(root,text='韵母').place(x=200,y=90,anchor=\"center\")\n",
    "FNL_EXCEP=StringVar()\n",
    "FNL_EXCEP.set(0)\n",
    "Entry(root,textvariable=FNL_EXCEP,width=4).place(x=250,y=90,anchor=\"center\")\n",
    "Label(root,text='声调').place(x=300,y=90,anchor=\"center\")\n",
    "TONE_EXCEP=StringVar()\n",
    "TONE_EXCEP.set(0)\n",
    "Entry(root,textvariable=TONE_EXCEP,width=4).place(x=350,y=90,anchor=\"center\")\n",
    "\n",
    "choose_file_btn=Button(root,text=\"选择源文件\",command=choose_files)\n",
    "choose_file_btn.place(x=50,y=120,anchor=\"center\")\n",
    "execute_btn=Button(root,text=\"开始分析\",command=execute)\n",
    "execute_btn.place(x=140,y=120,anchor=\"center\")\n",
    "Label(root,text='@Hue Zhang 制作\\n如有问题请联系:3275803255@qq.com').place(x=300,y=120,anchor=\"center\")\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
